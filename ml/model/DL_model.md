Вот улучшенная версия отчёта — формально, логично и без признаков автогенерации:

---

# Отчёт о результатах обучения и оценки DL-моделей

В рамках эксперимента были протестированы три модели глубокого обучения для задачи регрессии: **MLPRegressor**, **TabNetRegressor** и **DeepKAN**. Все модели обучались на одной и той же выборке с масштабированием признаков и целевой переменной, а также с одними и теми же метриками оценки: `MSE`, `MAPE` и `R²`.

## Конфигурация

* Размер обучающей выборки: 92 017 объектов
* Количество признаков: 62
* Целевая переменная: цена (восстановлена из стандартизованного масштаба)
* Аппаратная среда: GPU (T4)

---

## Результаты моделей

### Модель: **MLPRegressor**

* Архитектура: 2 скрытых слоя по 64 нейрона
* Оптимизатор: Adam
* Количество эпох: 20

**Оценка на тестовой выборке:**

* MSE: 23.34 трлн
* MAPE: 14.84%
* R²: 0.9016

---

### Модель: **TabNetRegressor**

* Параметры: `max_epochs=100`, `patience=10`, `batch_size=256`, `virtual_batch_size=128`
* Использовалась ранняя остановка

**Оценка на тестовой выборке:**

* MSE: 23.40 трлн
* MAPE: 15.70%
* R²: 0.9013

---

### Модель: **DeepKAN**

* Архитектура: hidden\_layers=\[64, 64, 1]
* Количество эпох: 20

**Оценка на тестовой выборке:**

* MSE: 23.31 трлн
* MAPE: 14.58%
* R²: 0.9017

---

## Сравнительный анализ

| Модель          | MSE            | MAPE       | R²         |
| --------------- | -------------- | ---------- | ---------- |
| MLPRegressor    | 23.34 трлн     | 14.84%     | 0.9016     |
| TabNetRegressor | 23.40 трлн     | 15.70%     | 0.9013     |
| DeepKAN         | **23.31 трлн** | **14.58%** | **0.9017** |

---

## Выводы

* Все три модели продемонстрировали сопоставимое качество предсказаний, с R² около 0.90, что говорит о высоком уровне объяснённой дисперсии.
* **DeepKAN** продемонстрировала наилучшие метрики на тестовой выборке, опередив TabNet и MLP как по MAPE, так и по R².
* **MLPRegressor** показал стабильные результаты, уступив DeepKAN совсем незначительно.
* **TabNetRegressor**, несмотря на сложную архитектуру и табличную специфику, не превзошёл более простые модели и продемонстрировал немного более высокую ошибку.

## Заключение

Все протестированные архитектуры способны решать задачу с приемлемым качеством. **DeepKAN** и **MLP** выделяются как наиболее точные решения, и их можно рекомендовать в качестве базовых моделей для дальнейшего улучшения, в том числе при сравнении с градиентным бустингом (например, XGBoost), который в отдельных экспериментах показал лучшие результаты.
