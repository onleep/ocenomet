# Отчет о результатах обучения и оценки DL моделей

В ходе эксперимента были обучены следующие модели:

- **DeepKAN**
- **TabNetRegressor**
- **MLPRegressor**

## Результаты экспериментов

### Модель: **MLPRegressor**
- **optimizer = optim.Adam, 20 эпох:**
  - Test MSE: 23341461143552.0000
  - Test MAPE: 14.84%
  - Test R²: 0.9016

---

### Модель: **TabNetRegressor**
- **max_epochs=100:**
- **patience=10:**
- **batch_size=256:**
- **virtual_batch_size=128:**
  - Test MSE: 23397748162420.6562
  - Test R²: 0.9013
  - Test MAPE: 15.70%

---

### Модель: **DeepKAN**
- **20 эпох:**
    - Test MSE: 23317098528768.0000
    - Test MAPE: 14.58%
    - Test R²: 0.9017

---

## Выводы

-  Модель **MLPRegressor** показала отличные результаты, с R2 на уровне 0.9016 и MAPE 14.84%. Это говорит о том, что она хорошо справляется с задачей предсказания на тестовых данных.
-  **DeepKAN** немного опередила **TabNetRegressor**, достигнув R2 0.9017 и MAPE 14.58%. Это делает её самой эффективной моделью среди протестированных.
-  **TabNetRegressor** показала результаты, близкие к другим моделям, но с чуть более низкими показателями: R2 0.9013 и MAPE 15.70%.

**Итог:** Все три модели имеют схожие значения MSE, что указывает на похожий уровень ошибок в предсказаниях. Однако **DeepKAN** и **MLPRegressor** демонстрируют более низкие значения MAPE. В общем, модели справляются с задачей, но **DeepKAN** и **MLPRegressor** являются лучшими вариантами сравнимимы с xgboost (а он показал суперские результаты).
